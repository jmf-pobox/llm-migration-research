% Bibliography for Cross-Language Code Migration paper

% Foundational LLM/Transformer papers
@inproceedings{vaswani2017attention,
  title={Attention is All You Need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

% Code generation benchmarks and models
@article{chen2021codex,
  title={Evaluating Large Language Models Trained on Code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@article{li2022alphacode,
  title={Competition-Level Code Generation with {AlphaCode}},
  author={Li, Yujia and Choi, David and Chung, Junyoung and Kushman, Nate and Schrittwieser, Julian and Leblond, R{\'e}mi and Eccles, Tom and Keeling, James and Gimeno, Felix and Dal Lago, Agustin and others},
  journal={Science},
  volume={378},
  number={6624},
  pages={1092--1097},
  year={2022},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{jimenez2024swebench,
  title={{SWE}-bench: Can Language Models Resolve Real-World {GitHub} Issues?},
  author={Jimenez, Carlos E. and Yang, John and Wettig, Alexander and Yao, Shunyu and Pei, Kexin and Press, Ofir and Narasimhan, Karthik},
  booktitle={International Conference on Learning Representations},
  year={2024}
}

% Long context and attention behavior
@article{liu2024lost,
  title={Lost in the Middle: How Language Models Use Long Contexts},
  author={Liu, Nelson F. and Lin, Kevin and Hewitt, John and Paranjape, Ashwin and Bevilacqua, Michele and Petroni, Fabio and Liang, Percy},
  journal={Transactions of the Association for Computational Linguistics},
  volume={12},
  pages={157--173},
  year={2024}
}

% Emergent abilities
@article{wei2022emergent,
  title={Emergent Abilities of Large Language Models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal={Transactions on Machine Learning Research},
  year={2022}
}

@inproceedings{schaeffer2023emergent,
  title={Are Emergent Abilities of Large Language Models a Mirage?},
  author={Schaeffer, Rylan and Miranda, Brando and Koyejo, Sanmi},
  booktitle={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}

% Multi-agent LLM systems for software engineering
@inproceedings{hong2024metagpt,
  title={{MetaGPT}: Meta Programming for A Multi-Agent Collaborative Framework},
  author={Hong, Sirui and Zhuge, Mingchen and Chen, Jonathan and Zheng, Xiawu and Cheng, Yuheng and Zhang, Ceyao and Wang, Jinlin and Wang, Zili and Yau, Steven Ka Shing and Lin, Zijuan and others},
  booktitle={International Conference on Learning Representations},
  year={2024}
}

@article{qian2024chatdev,
  title={{ChatDev}: Communicative Agents for Software Development},
  author={Qian, Chen and Liu, Wei and Liu, Hongzhang and Chen, Nuo and Dang, Yufan and Li, Jiahao and Yang, Cheng and Chen, Weize and Su, Yusheng and Cong, Xin and others},
  journal={arXiv preprint arXiv:2307.07924},
  year={2024}
}

% Rule-based transformation systems
@article{cordy2006txl,
  title={{TXL}---A Language for Programming Language Tools and Applications},
  author={Cordy, James R.},
  journal={Electronic Notes in Theoretical Computer Science},
  volume={110},
  pages={3--31},
  year={2006},
  publisher={Elsevier}
}

@inproceedings{visser2004stratego,
  title={Program Transformation with {Stratego/XT}},
  author={Visser, Eelco},
  booktitle={Domain-Specific Program Generation},
  pages={216--238},
  year={2004},
  publisher={Springer}
}

@inproceedings{klint2009rascal,
  title={{RASCAL}: A Domain Specific Language for Source Code Analysis and Manipulation},
  author={Klint, Paul and van der Storm, Tijs and Vinju, Jurgen},
  booktitle={Ninth IEEE International Working Conference on Source Code Analysis and Manipulation},
  pages={168--177},
  year={2009},
  organization={IEEE}
}

% LLM-based code translation
@article{pan2024llmtranslation,
  title={Exploring and Unleashing the Power of Large Language Models in Automated Code Translation},
  author={Pan, Zhen and Lu, Shuai and Lyu, Michael R.},
  journal={Proceedings of the ACM on Software Engineering},
  volume={1},
  number={FSE},
  year={2024},
  publisher={ACM}
}

% Multi-agent code translation
@article{yuan2024transagent,
  title={{TransAGENT}: An {LLM}-Based Multi-Agent System for Code Translation},
  author={Yuan, Zhiqiang and Chen, Weitong and Wang, Hanlin and Yu, Kai and Peng, Xin and Lou, Yiling},
  journal={arXiv preprint arXiv:2409.19894},
  year={2024}
}

% Large-scale industrial migration
@inproceedings{ziftci2025google,
  title={Migrating Code At Scale With {LLMs} At {Google}},
  author={Ziftci, Celal and Cavalcanti, Diego and Fourrier, Cl\'{e}mentine and Schaef, Martin},
  booktitle={Proceedings of the 33rd ACM International Conference on the Foundations of Software Engineering},
  year={2025},
  organization={ACM}
}

% Claude Agent SDK
@misc{anthropic2024sdk,
  title={Claude Agent {SDK} Documentation},
  author={{Anthropic}},
  year={2024},
  howpublished={\url{https://github.com/anthropics/claude-code}}
}

% Rust reference
@misc{rust2024,
  title={The {Rust} Reference},
  author={{The Rust Programming Language}},
  year={2024},
  howpublished={\url{https://doc.rust-lang.org/reference/}}
}
